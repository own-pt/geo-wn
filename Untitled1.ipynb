{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import pprint\n",
    "from rdflib import Literal\n",
    "from rdflib.namespace import Namespace, URIRef\n",
    "from rdflib.namespace import SKOS\n",
    "from rdflib.plugins import sparql\n",
    "import re\n",
    "\n",
    "#namespaces\n",
    "wn30 = Namespace(\"https://w3id.org/own-pt/wn30/schema/\")\n",
    "wn30_instance = Namespace(\"https://w3id.org/own-pt/wn30-en/instances/\")\n",
    "thors = Namespace(\"http://resource.geosciml.org/ontology/timescale/thors/\")\n",
    "gts= Namespace(\"http://resource.geosciml.org/ontology/ti1mescale/gts/#\")\n",
    "ex=  Namespace(\"http://www.ibm.com/mapping/\")\n",
    "gts= Namespace(\"http://resource.geosciml.org/ontology/timescale/gts/\")\n",
    "isc= Namespace('http://resource.geosciml.org/classifier/ics/ischart/')\n",
    "wn30en= Namespace('https://w3id.org/own-pt/wn30-en/instances/')\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "rdf = Namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N4f74b2137b3b45ca91b4a22f8504dd0d (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read wn\n",
    "wn = rdflib.Graph()\n",
    "wn.parse(\"FGV/openWordnet-PT/wordnet-en.nt\",format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Na57524c890b442b4a52db6ad80e5ba40 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read isc \n",
    "isc2014 = rdflib.Graph()\n",
    "isc2014.parse(\"FGV/isc2014.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nc60219d034f043a6ba01375c2ac1d4db (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read mapping isc - openwordnet\n",
    "mapping = rdflib.Graph()\n",
    "mapping.parse('FGV/geo-wn/mapping.ttl', format='ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N89863498ebee4b7f9d9017702099a7cd (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read noun.geotime\n",
    "noungeo = rdflib.Graph()\n",
    "noungeo.parse(\"noun.geotime.nt\",format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eras_which_is(rank_isc):\n",
    "    \"\"\"\n",
    "    This function returns a list of all eras which has rank predicate equal to the passed to hte function.\n",
    "    \"\"\"\n",
    "    eras_list = []\n",
    "    query_ga_label_era = sparql.prepareQuery(\n",
    "        \"\"\" \n",
    "        select ?la where {\n",
    "        ?ga a <http://resource.geosciml.org/ontology/timescale/gts#GeochronologicEra> .\n",
    "        ?ga <http://resource.geosciml.org/ontology/ti1mescale/gts#rank> <http://resource.geosciml.org/ontology/timescale/%s> .\n",
    "        ?ga <http://www.w3.org/2004/02/skos/core#prefLabel> ?la . \n",
    "        FILTER langMatches( lang(?la), \"en\") .}\n",
    "        \"\"\" % rank_isc)\n",
    "\n",
    "    for a in isc2014.query(query_ga_label_era):\n",
    "        eras_list.append(str(a[0]))\n",
    "    return(eras_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection_isc_wn(they_are_instance_of, eras_list, eras_synsets, eras_with_synset):\n",
    "    for era in eras_list: \n",
    "        st = \"\"\"\n",
    "            select ?ssa where{\n",
    "            ?ssa <https://w3id.org/own-pt/wn30/schema/containsWordSense> ?b .\n",
    "            <https://w3id.org/own-pt/wn30-en/instances/%s> <https://w3id.org/own-pt/wn30/schema/hasInstance> ?ssa .       \n",
    "            ?b <http://www.w3.org/2000/01/rdf-schema#label> %s . }\n",
    "            \"\"\" % (they_are_instance_of, ('\"' + era + '\"'))\n",
    "   \n",
    "        query = sparql.prepareQuery(st)\n",
    "\n",
    "        for a in wn.query(query):\n",
    "            if not era in eras_synsets:\n",
    "                eras_synsets[era]= a[0]\n",
    "                eras_with_synset.append(era)\n",
    "                \n",
    "def make_mapping(dic, lista,graph):\n",
    "    for i in range(0,len(dic)):\n",
    "        graph.add((isc[lista[i]], ex['mapsTo'], dic[lista[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding Super Eon\n",
    "super_eons = eras_which_is('rank/Super-Eon')\n",
    "they_are_instance_of = 'synset-15243730-n'\n",
    "super_eons_synset = dict()\n",
    "super_eons_with_synset = []\n",
    "intersection_isc_wn(they_are_instance_of, super_eons, super_eons_synset, super_eons_with_synset)\n",
    "make_mapping(super_eons_synset,super_eons_with_synset, mapping)\n",
    "\n",
    "#adding Eon \n",
    "eons = eras_which_is(\"rank/Eon\")\n",
    "they_are_instance_of = 'synset-15243730-n'\n",
    "eons_synset = dict()\n",
    "eons_with_synset = []\n",
    "intersection_isc_wn(they_are_instance_of, eons, eons_synset, eons_with_synset)\n",
    "make_mapping(eons_synset,eons_with_synset, mapping)\n",
    "\n",
    "#adding Period \n",
    "periods = eras_which_is('rank/Period')  \n",
    "they_are_instance_of = 'synset-15247518-n'\n",
    "periods_synset = dict()\n",
    "periods_with_synset = []\n",
    "intersection_isc_wn(they_are_instance_of, periods, periods_synset, periods_with_synset)\n",
    "make_mapping(periods_synset,periods_with_synset, mapping)\n",
    "\n",
    "#adding Epoch\n",
    "epochs = eras_which_is('rank/Epoch')\n",
    "they_are_instance_of = 'synset-15248269-n'\n",
    "epochs_synset = dict()\n",
    "epochs_with_synset = []\n",
    "intersection_isc_wn(they_are_instance_of, epochs, epochs_synset, epochs_with_synset)\n",
    "make_mapping(epochs_synset,epochs_with_synset, mapping)\n",
    "\n",
    "#adding Era\n",
    "eras = eras_which_is('gts#Era')\n",
    "they_are_instance_of = 'synset-15248020-n'\n",
    "eras_synset = dict()\n",
    "eras_with_synset = []\n",
    "intersection_isc_wn(they_are_instance_of, eras, eras_synset, eras_with_synset)\n",
    "make_mapping(eras_synset,eras_with_synset, mapping)\n",
    "\n",
    "#adding Stages\n",
    "ages = eras_which_is(\"rank/Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/own-pt/wn30-en/instances/synset-15127729-n\n",
      "https://w3id.org/own-pt/wn30-en/instances/synset-15125097-n\n",
      "https://w3id.org/own-pt/wn30-en/instances/synset-15127507-n\n"
     ]
    }
   ],
   "source": [
    "# How many geo eras has on wn?\n",
    "\n",
    "query_ga_wn = sparql.prepareQuery(\n",
    "    \"\"\" \n",
    "    select ?ssa where {\n",
    "    <https://w3id.org/own-pt/wn30-en/instances/synset-15116283-n> <https://w3id.org/own-pt/wn30/schema/hypernymOf> ?gs .\n",
    "    ?gs <https://w3id.org/own-pt/wn30/schema/hasInstance> ?ssa .}\n",
    "    \"\"\")\n",
    "\n",
    "l = [] \n",
    "for a in wn.query(query_ga_wn):\n",
    "        l.append(a[0])\n",
    "        \n",
    "# What are synsets wich in wn but are not in mapping?\n",
    "synsets = []\n",
    "for i in super_eons_synset:\n",
    "    synsets.append(super_eons_synset[i])\n",
    "for i in eons_synset:\n",
    "    synsets.append(eons_synset[i])\n",
    "for i in periods_synset:\n",
    "    synsets.append(periods_synset[i])\n",
    "for i in epochs_synset:\n",
    "    synsets.append(epochs_synset[i])\n",
    "for i in eras_synset:\n",
    "    synsets.append(eras_synset[i])\n",
    "    \n",
    "for a in l:\n",
    "    if not a in synsets:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until here was done the mapping  between openWordnet and isc of what already has on wn. Now, we are goint to add whats is missing and mappiing it, but  mapping will be between wn-txt and isc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N62ed5aac90b44f5da13139f76defa3a6 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = rdflib.Graph()\n",
    "mapping.parse('mapping-txt-isc.ttl', format='ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nbbd6719453864a45aca250a271a2f2b9 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noungeo = rdflib.Graph()\n",
    "noungeo.parse(\"noun.geotime.nt\",format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(lista, graph):\n",
    "    \"\"\"\n",
    "    This function remove duplicates and what is not part of a URI in isc2014.\n",
    "    \"\"\"\n",
    "    lista = list(map(lambda x: x.replace(\" \", \"\").replace(\"Late/\", \"\").replace(\"Early/\", \"\").replace(\"-\", \"\") , lista))\n",
    "    for i in lista:\n",
    "        if not (isc[i], None, None) in graph:\n",
    "            lista.remove(i)\n",
    "    lista = list(set(lista))\n",
    "    return(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eras_clean = clean(eras, isc2014)\n",
    "eras_clean = clean(eras_clean, isc2014)\n",
    "super_eons_clean = clean(super_eons, isc2014)\n",
    "epochs_clean = clean(epochs, isc2014)\n",
    "periods_clean = clean(periods,isc2014)\n",
    "eons_clean = clean(eons, isc2014)\n",
    "ages_clean = clean(ages, isc2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_synsets(lista, syn_graph, knowledge_graph, mapping_graph, hypernymOf):\n",
    "    \"\"\"\n",
    "    Add what aren't on wn yet. \n",
    "    \"\"\"\n",
    "    for synset_id_durty in lista:\n",
    "        synset_id = clean_word(synset_id_durty)\n",
    "        synset_uri = wn30_instance[\"synset-noun.geotime-%s\" % synset_id]\n",
    "        if not (synset_uri, None, None) in syn_graph:\n",
    "            mapping_graph.add((isc[synset_id_durty], ex['mapsTo'], synset_uri))\n",
    "            syn_graph.add((synset_uri, rdf[\"type\"], wn30[\"NounSynset\"]))\n",
    "            syn_graph.add((synset_uri, wn30[\"hypernymOf\"], wn30_instance[\"synset-noun.geotime-%s\" % hypernymOf]))\n",
    "            add_broader(synset_id,synset_id_durty, synset_uri, syn_graph, knowledge_graph, mapping_graph)\n",
    "            add_gloss(synset_uri,synset_id_durty, synset_id, knowledge_graph, syn_graph)\n",
    "            add_wordsenses(synset_id, synset_uri, syn_graph, knowledge_graph, mapping_graph, type)            \n",
    "        else:\n",
    "            add_broader(synset_id,synset_id_durty, synset_uri, syn_graph, knowledge_graph, mapping_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_broader(synset_id, synset_id_durty,synset_uri, syn_graph, knowledge_graph, mapping_graph):\n",
    "    for s, p, broader in knowledge_graph.triples((isc[synset_id_durty], skos[\"broader\"], None)):\n",
    "        for lixo3, lixo4, synset in mapping_graph.triples((broader, ex['mapsTo'], None)):\n",
    "            if not (synset_uri, wn30[\"partHolonymOf\"], synset) in syn_graph:\n",
    "                syn_graph.add((synset_uri, wn30[\"partHolonymOf\"], synset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_wordsenses(synset_id, synset_uri, syn_graph, knowledge_graph, mapping_graph, type):\n",
    "    add_wordsense(synset_id, synset_uri, syn_graph, knowledge_graph, mapping_graph)\n",
    "    add_wordsense(\"%s_%s\" % (synset_id, type), synset_uri, syn_graph, knowledge_graph, mapping_graph)\n",
    "    if \"Upper\" in synset_id:\n",
    "            add_wordsense(re.sub(\"Upper\", \"Late\", synset_id), synset_uri, syn_graph, knowledge_graph, mapping_graph)\n",
    "    if \"Lower\" in synset_id:\n",
    "            add_wordsense(re.sub(\"Lower\", \"Early\", synset_id), synset_uri, syn_graph, knowledge_graph, mapping_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_wordsense(sense_id, synset_uri, syn_graph, knowledge_graph, mapping_graph):\n",
    "    wordsense_uri = wn30_instance[\"wordsense-noun.geotime-%s\" % sense_id]\n",
    "    word_uri = wn30_instance[\"word-%s\" % sense_id]\n",
    "    syn_graph.add((synset_uri, wn30[\"containsWordSense\"],wordsense_uri))\n",
    "    syn_graph.add((wordsense_uri, rdf[\"type\"], wn30[\"WordSense\"]))\n",
    "    syn_graph.add((wordsense_uri, wn30[\"word\"], word_uri))\n",
    "    syn_graph.add((word_uri, rdf[\"type\"], wn30[\"Word\"]))\n",
    "    syn_graph.add((word_uri, wn30[\"lexicalform\"], Literal(re.sub(\"_\", \" \", sense_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_gloss(synset_uri,synset_id_durty, synset_id, knowledge_graph, syn_graph):\n",
    "    query = sparql.prepareQuery(\n",
    "    \"\"\" \n",
    "    select ?c where {\n",
    "    <http://resource.geosciml.org/classifier/ics/ischart/%s> <http://www.w3.org/2000/01/rdf-schema#comment> ?c .}\n",
    "    \"\"\" % synset_id_durty)\n",
    "    for_gloss =[]\n",
    "    for a in knowledge_graph.query(query):\n",
    "        if re.search(\"[a-z]-(.*)\", a[0].capitalize()):\n",
    "            for_gloss.append(re.search(\"[a-z]-(.*)\", a[0].capitalize()).group(1))\n",
    "    if len(for_gloss) > 1:\n",
    "        syn_graph.add((synset_uri, wn30[\"gloss\"], Literal(\"from %s million to %s million years ago\" %(for_gloss[0], for_gloss[1] ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    matchs = re.search(\"([A-Z][a-z]*)([A-Z][a-z]*)?([A-Z][a-z]*)?(\\d)?\", word).groups()\n",
    "    a = matchs[0]\n",
    "    for l in range(1,4):\n",
    "        if matchs[l]:\n",
    "            a = a + \"_\" + matchs[l]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_synsets(eons_clean, noungeo, isc2014, mapping, \"eon\")\n",
    "add_synsets(eras_clean, noungeo, isc2014, mapping, \"era\")\n",
    "add_synsets(periods_clean, noungeo, isc2014, mapping, \"period\")\n",
    "add_synsets(epochs_clean, noungeo, isc2014, mapping, \"epoch\")\n",
    "add_synsets(ages_clean, noungeo, isc2014, mapping, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noungeo.serialize(destination='new-noun.geotime.nt', format='nt')\n",
    "mapping.serialize(destination='new-mapping-txt-isc.ttl', format='ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
